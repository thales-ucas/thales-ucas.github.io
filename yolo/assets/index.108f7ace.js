var Z=Object.defineProperty;var U=(a,e,o)=>e in a?Z(a,e,{enumerable:!0,configurable:!0,writable:!0,value:o}):a[e]=o;var b=(a,e,o)=>(U(a,typeof e!="symbol"?e+"":e,o),o);import{l as N,t as O,f as T,s as ee,d as se,a as te,m as ae,i as oe,g as L,b as Y,c as v,e as F,r as B,h as q,j as E,k as y,n as M,o as H,p as j,q as ie,u as re,v as ne,w as X,x as D,y as S,z as ce,A as R,B as f,C as x,D as p,E as P,F as A,G as z,H as W,I as $,J as le,K as de,L as ue,M as he,N as K,O as G,P as pe,Q as me,R as ge,S as fe}from"./vendor.cec17c4c.js";const ve=function(){const e=document.createElement("link").relList;if(e&&e.supports&&e.supports("modulepreload"))return;for(const s of document.querySelectorAll('link[rel="modulepreload"]'))n(s);new MutationObserver(s=>{for(const t of s)if(t.type==="childList")for(const r of t.addedNodes)r.tagName==="LINK"&&r.rel==="modulepreload"&&n(r)}).observe(document,{childList:!0,subtree:!0});function o(s){const t={};return s.integrity&&(t.integrity=s.integrity),s.referrerpolicy&&(t.referrerPolicy=s.referrerpolicy),s.crossorigin==="use-credentials"?t.credentials="include":s.crossorigin==="anonymous"?t.credentials="omit":t.credentials="same-origin",t}function n(s){if(s.ep)return;s.ep=!0;const t=o(s);fetch(s.href,t)}};ve();var be="./assets/logo.031fa3c3.jpeg",ye="./assets/tflogo.45a905ce.jpg";const V={v3tiny:{path:"models/yolov3-tiny/model.json",indexedDB:"indexeddb://yolov3-tiny"}},xe=[10,14,23,27,37,58,81,82,135,169,344,319],_e={"3":[[6,7,8],[3,4,5],[0,1,2]],"2":[[3,4,5],[1,2,3]]},J=["person","bicycle","car","motorbike","aeroplane","bus","train","truck","boat","traffic light","fire hydrant","stop sign","parking meter","bench","bird","cat","dog","horse","sheep","cow","elephant","bear","zebra","giraffe","backpack","umbrella","handbag","tie","suitcase","frisbee","skis","snowboard","sports ball","kite","baseball bat","baseball glove","skateboard","surfboard","tennis racket","bottle","wine glass","cup","fork","knife","spoon","bowl","banana","apple","sandwich","orange","broccoli","carrot","hot dog","pizza","donut","cake","chair","sofa","pottedplant","bed","diningtable","toilet","tvmonitor","laptop","mouse","remote","keyboard","cell phone","microwave","oven","toaster","sink","refrigerator","book","clock","vase","scissors","teddy bear","hair drier","toothbrush"];class we{constructor(){b(this,"model");b(this,"canvas",document.createElement("canvas"));b(this,"params",{maxBoxes:20,scoreThreshold:.2,iouThreshold:.3,inputSize:416,numClasses:J.length,classNames:J,anchors:xe});b(this,"msg");this.msg="start"}async init(){}async loadModel(e,o){try{this.model=await N(e.indexedDB,o)}catch{this.model=await N(e.path,o),this.model.save(e.indexedDB)}return this.model}async predict(e){let o=O(()=>{var i;this.canvas.width=this.params.inputSize,this.canvas.height=this.params.inputSize;const s=this.canvas.getContext("2d");s==null||s.drawImage(e,0,0,this.params.inputSize,this.params.inputSize);let t=T(this.canvas,3);return t=t.expandDims(0).toFloat().div(ee(255)),(i=this.model)==null?void 0:i.predict(t)});const n=await this.postprocess(o,[e.videoHeight||e.height,e.videoWidth||e.width]);return se(o),n}async postprocess(e,o){const[n,s]=this.yoloEval(e,o);let t=[],r=[],i=[];const h=te(s,-1),c=ae(s,-1),l=await oe.nonMaxSuppressionAsync(n,c,this.params.maxBoxes,this.params.iouThreshold,this.params.scoreThreshold);return l.size&&O(()=>{const d=L(n,l),m=L(c,l);d.split(l.size).map(u=>{t.push(u.dataSync())}),m.dataSync().map(u=>{r.push(u)}),i=h.gather(l).dataSync()}),c.dispose(),h.dispose(),l.dispose(),n.dispose(),s.dispose(),t.map((d,m)=>{const u=Math.max(0,d[0]),_=Math.max(0,d[1]),w=Math.min(o[0],d[2]),k=Math.min(o[1],d[3]),C=w-u,Q=k-_;return{top:u,left:_,bottom:w,right:k,height:C,width:Q,score:r[m],classIndex:i[m],class:this.params.classNames[i[m]]}})}yoloEval(e,o){return O(()=>{let n=1,s,t;n=e.length,t=_e[n],s=e[0].shape.slice(1,3).map(c=>c*32);const r=Y(this.params.anchors).reshape([-1,2]);let i=[],h=[];for(let c=0;c<n;c++){const[l,d]=this.yoloBoxesAndScores(e[c],r.gather(Y(t[c],"int32")),s,o);i.push(l),h.push(d)}return i=v(i),h=v(h),[i,h]})}yoloBoxesAndScores(e,o,n,s){const[t,r,i,h]=this.yoloHead(e,o,n);let c=this.yoloCorrectBoxes(t,r,s);c=c.reshape([-1,4]);let l=F(i,h);return l=B(l,[-1,this.params.numClasses]),[c,l]}yoloHead(e,o,n){const s=o.shape[0],t=B(o,[1,1,s,2]),r=e.shape.slice(1,3),i=q(B(E(0,r[0]),[-1,1,1,1]),[1,r[1],1,1]),h=q(B(E(0,r[1]),[1,-1,1,1]),[r[0],1,1,1]),c=v([h,i],3).cast(e.dtype);e=e.reshape([r[0],r[1],s,this.params.numClasses+5]);const[l,d,m,u]=y(e,[2,2,1,this.params.numClasses],3),_=M(H(j(l),c),r.reverse()),w=M(F(ie(d),t),n.reverse()),k=j(m);let C;return C=j(u),[_,w,k,C]}yoloCorrectBoxes(e,o,n){let s=v(y(e,2,3).reverse(),3),t=v(y(o,2,3).reverse(),3);const r=F(re(s,M(t,2)),n),i=F(H(s,M(t,2)),n);return v([...y(r,2,3),...y(i,2,3)],3)}}var g=(a=>(a[a.none=0]="none",a[a.error=1]="error",a[a.loading=2]="loading",a[a.ready=3]="ready",a[a.executing=4]="executing",a))(g||{});const I=new we,ke=ne({id:"Yolo",state:()=>({status:g.none,fraction:0,colors:{},scaleW:0,scaleH:0,animateId:0,duration:100,expire:100,image:{},boxes:[],msg:""}),getters:{isInit(){return this.status===g.none||this.status===g.error},isLoading(){return this.status===g.loading},loadingPercent(){return`${(this.fraction*100).toFixed(2)}%`},isExecuting(){return this.status===g.executing},labels(){const a=this.boxes,e=this.image.clientWidth,o=this.image.clientHeight,n=this.image.videoWidth,s=this.image.videoHeight,t=e/n,r=o/s;return a.forEach(i=>{i.class in this.colors||(this.colors[i.class]="#"+Math.floor(Math.random()*16777215).toString(16)),i.transform=`translate(${i.left*t}px, ${i.top*r}px)`,i.width=`${i.width*t-4}px`,i.height=`${i.height*r-4}px`,i.percent=`${(i.score*100).toFixed(2)}%`,i.color=this.colors[i.class]}),a},models(){return V}},actions:{async load(){return this.status=g.loading,await I.loadModel(V.v3tiny,{onProgress:a=>this.fraction=a}),this.status=g.ready,!0},start(a=100){this.duration=a,this.animateId=requestAnimationFrame(this.animate)},stop(){cancelAnimationFrame(this.animateId)},animate(){Date.now()>this.expire?I.predict(this.image).then(e=>{this.boxes=e,this.expire=Date.now()+this.duration,this.animateId=requestAnimationFrame(this.animate)}):this.animateId=requestAnimationFrame(this.animate)},init(a){this.image=a,I.init()}}});navigator.mediaDevices===void 0&&(navigator.mediaDevices={});navigator.mediaDevices.getUserMedia===void 0&&(navigator.mediaDevices.getUserMedia=function(a){var e=navigator.webkitGetUserMedia||navigator.mozGetUserMedia;return e?new Promise(function(o,n){e.call(navigator,a,o,n)}):Promise.reject(new Error("getUserMedia is not implemented in this browser"))});const Ce={class:"ai989"},Fe=p("header",null,[p("img",{src:be}),p("img",{src:ye})],-1),Be=p("article",null,[p("h1",null,"\u667A\u80FD\u8F6C\u552E"),p("p",null,"\u6253\u5F00\u6444\u50CF\u5934\uFF0C\u5F00\u59CB\u626B\u63CF\u5546\u54C1")],-1),Me=p("legend",null,"\u6444\u50CF\u5934\u591A\u76EE\u6807\u8BC6\u522B",-1),De={key:0},Pe=K("\u542F\u52A8"),ze={class:"container"},Oe={class:"wrapper"},je={class:"labels"},Ae=he('<fieldset><legend>\u6E90\u7801</legend><ul><li><a href="https://gitee.com/thales-ucas/smarty-resale-vue.git" target="_blank">https://gitee.com/thales-ucas/smarty-resale-vue.git</a></li><li><a href="https://github.com/thales-ucas/smarty-resale-vue.git" target="_blank">https://github.com/thales-ucas/smarty-resale-vue.git</a></li></ul></fieldset><fieldset><legend>\u53C2\u8003\u6587\u732E</legend><h2><a href="https://arxiv.org/abs/1506.02640" target="_blank">You Only Look Once: Unified, Real-Time Object Detection</a></h2><h3><span class="descriptor">Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Redmon%2C+J">Joseph Redmon</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Divvala%2C+S">Santosh Divvala</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Girshick%2C+R">Ross Girshick</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Farhadi%2C+A">Ali Farhadi</a></h3><p>We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. </p><p>Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset. </p></fieldset>',2),Ie=X({setup(a){const e=ke(),o=D(()=>e.isInit),n=D(()=>e.isLoading),s=D(()=>e.loadingPercent),t=S(),r=S(null),i=D(()=>e.labels);function h(c){var l;e.load().then(d=>{e.start()}),(l=navigator==null?void 0:navigator.mediaDevices)==null||l.getUserMedia({audio:!1,video:{facingMode:"environment"}}).then(d=>{t.value?"srcObject"in t.value?(t.value.srcObject=d,r.value=null):r.value="srcObject\u5C5E\u6027\u7F3A\u5931":r.value="video\u5143\u7D20\u4E0D\u5B58\u5728"}).catch(d=>{r.value=d.message})}return ce(()=>{t.value&&e.init(t.value)}),(c,l)=>{const d=R("van-button"),m=R("van-loading");return f(),x("div",Ce,[Fe,Be,p("fieldset",null,[Me,r.value?(f(),x("div",De,P(r.value),1)):A("",!0),z(o)?(f(),W(d,{key:1,type:"primary",onClick:le(h,["stop"])},{default:$(()=>[Pe]),_:1},8,["onClick"])):A("",!0),z(n)?(f(),W(m,{key:2,type:"spinner"},{default:$(()=>[K("\u6A21\u578B\u52A0\u8F7D\u4E2D\u2026\u2026("+P(z(s))+")",1)]),_:1})):A("",!0),p("div",ze,[p("div",Oe,[p("div",je,[(f(!0),x(de,null,ue(z(i),u=>(f(),x("div",{class:"label",style:G({transform:u.transform,width:u.width,height:u.height,borderColor:u.color})},[p("div",{class:"text",style:G({color:u.color})},P(u.class)+" "+P(u.percent),5)],4))),256))]),p("video",{ref_key:"webcam",ref:t,autoplay:"",playsinline:"",muted:"",class:"webcam"},null,512)])])]),Ae])}}}),Ne=X({setup(a){return(e,o)=>(f(),x("div",null,[pe(Ie)]))}});me(Ne).use(ge()).use(fe).mount("#app");
